{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"2g\")\n",
    "    .config(\"spark.executer.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.parquet(\"../data/curated/full_data_without_fraud/\")\n",
    "\n",
    "# discard fraud transactions\n",
    "sdf = sdf.filter(F.col('is_fraud')==0)\n",
    "sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset \n",
    "train_sdf = sdf.filter((F.col('order_datetime') >= '2021-02-28') & (F.col('order_datetime') < '2021-08-28'))\n",
    "label_sdf = sdf.filter((F.col('order_datetime') >= '2022-02-28') & (F.col('order_datetime') < '2022-08-28'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sdf.count(), label_sdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created Features\n",
    "The following features are created by aggregating records from 2021-2 to 2021-8 for each merchant. They are used as features in the model.\n",
    "1. Total number of consumers\n",
    "2. Average transaction dollar value\n",
    "3. Total number of transactions\n",
    "4. Mean income of consumers\n",
    "5. revenue level\n",
    "6. BNPL revenue = take rate * total transaction\n",
    "7. Number of distinct postcode\n",
    "8. Tag (one hot encoding)\n",
    "\n",
    "The following features are created by aggregating records from 2022-2 to 2022-8 for each merchant. These features are to be predicted by the model and are used as features in the final ranking system.\n",
    "1. Total number of consumers\n",
    "2. BNPL revenue\n",
    "3. Total number of transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_sdf.groupBy('merchant_abn')\\\n",
    "      .agg(\n",
    "         F.countDistinct('consumer_id').alias('total_num_consumer'),\n",
    "         F.mean('dollar_value').alias('avg_dollar_value'),\n",
    "         F.countDistinct('order_id').alias('total_num_transaction'),\n",
    "         F.mean('mean_total_income').alias('mean_income'),\n",
    "         F.first('revenue_level').alias('revenue_level'),\n",
    "         F.sum(F.col('dollar_value') * F.col('take_rate')).alias('total_revenue'),\n",
    "         F.countDistinct('postcode').alias('total_num_postcode'),\n",
    "         F.first('tags').alias('tag'),\n",
    "      )\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label_sdf.groupBy('merchant_abn')\\\n",
    "      .agg(\n",
    "         F.countDistinct('consumer_id').alias('y_total_num_consumer'),\n",
    "         F.sum(F.col('dollar_value') * F.col('take_rate')).alias('y_total_revenue'),\n",
    "         F.countDistinct('order_id').alias('y_total_num_transaction')\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.count(), label.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.join(label, [\"merchant_abn\"], how=\"left\") \n",
    "# use left join here since if no historical data is provided, we cannot predict the future value of a merchant\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.write.format('parquet').mode('overwrite').save(\"../data/curated/train_data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "703e593df40508a60fa363339ca2bbb5bae045b0a530fb0e89bc3e7c255f1da9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
